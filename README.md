---
title: ContextAI
emoji: ğŸ¤–
colorFrom: blue
colorTo: green
sdk: docker
sdk_version: "1.0"
app_file: app.main
pinned: false
---
# ContextAI

A **FastAPI-based RAG application** that lets users upload documents (PDF/TXT) and ask questions.  
Powered by **LangChain**, **ChromaDB**, and **LLMs** for context-aware answers.

## ğŸš€ Live Demo

[![Live Demo](https://img.shields.io/badge/Demo-Live-brightgreen?style=for-the-badge)](https://rag-frontend-1y5k.onrender.com)


## ğŸ“š FastAPI RAG App with LangChain, ChromaDB & Authentication

This project is a Retrieval-Augmented Generation (RAG) web application built with FastAPI.
It allows users to:

- ğŸ”‘ Sign up / Sign in (JWT-based authentication)

- ğŸ“‚ Upload PDF or text documents

- ğŸ§  Store document embeddings in ChromaDB (vector database)

- ğŸ’¬ Ask questions about uploaded documents

- âš¡ Get context-aware answers powered by LangChain + LLMs (via OpenRouter
)

## ğŸš€ Features

- User authentication with access & refresh tokens

- Secure file uploads (.pdf, .txt)

- Automatic text chunking & embedding with HuggingFace models

- Persistent vector store using ChromaDB

- RAG pipeline with LangChainâ€™s RetrievalQA

- OpenRouter integration for running LLM queries

- CORS configured for frontend integration

## ğŸ› ï¸ Tech Stack

- FastAPI

- LangChain

- ChromaDB

- SQLModel
  -  for user database

- HuggingFace Embeddings

- OpenRouter
  -  (for LLM access)

## ğŸ“‚ Project Structure
`````
app/
 â”œâ”€â”€ main.py          # FastAPI routes & entrypoint
 â”œâ”€â”€ rag.py           # RAG pipeline (embeddings, vector store, QA chain)
 â”œâ”€â”€ models.py        # User models & schemas
 â”œâ”€â”€ auth.py          # Auth logic (hashing, tokens, verification)
 â”œâ”€â”€ database.py      # SQLModel setup
 â””â”€â”€ config.py        # Settings & constants
uploads/              # User uploaded files (ignored in Git)
chroma_db/            # Vector DB storage (ignored in Git)
`````

## âš™ï¸ Setup & Installation
1ï¸âƒ£ Clone the repo
  - git clone https://github.com/your-username/fastapi-rag-app.git
  - cd fastapi-rag-app

2ï¸âƒ£ Create & activate virtual environment
  - python -m venv venv
  - source venv/bin/activate   # Linux/Mac
  - venv\Scripts\activate      # Windows

3ï¸âƒ£ Install dependencies
  - pip install -r requirements.txt

4ï¸âƒ£ Configure environment variables

  - Create a .env file in the project root (or copy from .env.example):

  - ### OpenRouter
  - OPENROUTER=your_openrouter_api_key_here

  - ### JWT secret
  - SECRET_KEY=your_super_secret_key

âš ï¸ Never commit your real .env file.

â–¶ï¸ Run the App

  - Start the FastAPI server:

  - uvicorn app.main:app --reload


  - The API will be available at:
    - ğŸ‘‰ http://127.0.0.1:8000


## ğŸ”‘ Authentication Flow

  - Signup â†’ POST /signup with username & password

  - Signin â†’ POST /signin to receive access_token & refresh_token

  - Use Authorization: Bearer <access_token> for protected endpoints

## ğŸ“‚ Document Workflow

- User logs in

- Upload document â†’ POST /upload (PDF or TXT)

- Ask a question â†’ GET /ask?q=your+question

- The system searches your embeddings in ChromaDB and queries the LLM with context

## ğŸ“ Notes

- uploads/ and chroma_db/ are auto-created at runtime if they donâ€™t exist.

- Both folders are ignored by Git (runtime data only).

- Contributions & pull requests are welcome ğŸš€